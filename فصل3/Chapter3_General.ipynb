{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3\n",
    "\n",
    "## Overview of Machine Learning and Deep Learning Concepts\n",
    "\n",
    "This chapter is focused on exploring the realm of machine learning and deep learning algorithms. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries required for this chapter\n",
    "# Machine Learning Libraries: scikit-learn, keras and tensorflow\n",
    "\n",
    "# setting seed for model reproducibility\n",
    "!pip install scikeras\n",
    "seed_value = 42\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import normalize, Normalizer, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn.cluster as cluster\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from scikeras.wrappers import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical as np_utils\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style\n",
    "import seaborn as sns  # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# formatting for decimal places\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "plt.style.use(\"seaborn-v0_8-white\")\n",
    "sns.set_style(\"white\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------   For Google CoLab Only   --------\n",
    "## Run this cell to download the dataset automatically. Skip if you already have 'Merged_Data.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown --quiet\n",
    "import gdown\n",
    "\n",
    "\n",
    "url = ' https://drive.google.com/uc?id=1189ESk9vlZuklYHLhIlq_tJ61TSwMryY'\n",
    "gdown.download(url, 'Merged_Data.csv', quiet=False)\n",
    "\n",
    "data = pd.read_csv('Merged_Data.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell if you already have 'Merged_Data.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the .csv file as a dataframe - Raw Data File\n",
    "data = pd.read_csv('./data/Merged_Data.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Exploratory Data Analysis and Data Cleaning\n",
    "print(data.head(10))\n",
    "print('Shape of Dataset (rows,columns):', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point there is no data cleaning being performed. The objective of the next few sections is to wrangle the data and prepare it for the machine learning model stage. The current dataset consists of petrophysical properties from two different wells in Volve field. A majority of columns have float datatype except Well Name and Lithotype. In the case of regression problems, only quantitative columns would be considered, whereas in the case of classification, 'Lithotype' would be the response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of empty/NA values in each column\n",
    "data.isna().sum().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "data.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values\n",
    "data.nunique().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values\n",
    "data.nunique().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning - How many columns have Null or value=0\n",
    "data[data == 0].count(axis=0).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "print('Shape of Dataset (rows,columns):', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram - Distributions of continuous variables - only key features are shown here\n",
    "# sns.set(color_codes=True)\n",
    "f, axes = plt.subplots(3, 3, figsize=(15, 12), sharex=False)\n",
    "sns.distplot(data[\"DEPTH (M)\"], color=\"blue\", ax=axes[0, 0])\n",
    "sns.distplot(data[\"BVW (V/V)\"], color=\"olive\", ax=axes[0, 1])\n",
    "sns.distplot(data[\"KLOGH (MD)\"], color=\"teal\", ax=axes[0, 2])\n",
    "sns.distplot(data[\"PHIF (V/V)\"], color=\"blue\", ax=axes[1, 0])\n",
    "sns.distplot(data[\"RHOFL (G/CM3)\"], color=\"olive\", ax=axes[1, 1])\n",
    "sns.distplot(data[\"RW (OHMM)\"], color=\"teal\", ax=axes[1, 2])\n",
    "sns.distplot(data[\"SW (V/V)\"], color=\"blue\", ax=axes[2, 0])\n",
    "sns.distplot(data[\"VSH (V/V)\"], color=\"olive\", ax=axes[2, 1])\n",
    "sns.distplot(data[\"TEMP (DEGC)\"], color=\"teal\", ax=axes[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting some categorical variables\n",
    "sns.catplot(x=\"COAL_FLAG (UNITLESS)\", y=\"KLOGH (MD)\", data=data)\n",
    "# sns.catplot(x=\"SAND_FLAG (UNITLESS)\", y=\"KLOGH (MD)\", data=data)\n",
    "# sns.catplot(x=\"RHOFL (G/CM3)\", y=\"KLOGH (MD)\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['CARB_FLAG (UNITLESS)'].value_counts().plot(kind='bar')\n",
    "# data['COAL_FLAG (UNITLESS)'].value_counts().plot(kind='bar')\n",
    "data['SAND_FLAG (UNITLESS)'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots - Useful Tool to detect outliers\n",
    "f, axes = plt.subplots(3, 3, figsize=(12, 15), sharex=False)\n",
    "sns.boxplot(data[\"DEPTH (M)\"], color=\"blue\", ax=axes[0, 0])\n",
    "sns.boxplot(data[\"BVW (V/V)\"], color=\"olive\", ax=axes[0, 1])\n",
    "sns.boxplot(data[\"KLOGH (MD)\"], color=\"teal\", ax=axes[0, 2])\n",
    "sns.boxplot(data[\"PHIF (V/V)\"], color=\"blue\", ax=axes[1, 0])\n",
    "sns.boxplot(data[\"RHOFL (G/CM3)\"], color=\"olive\", ax=axes[1, 1])\n",
    "sns.boxplot(data[\"RW (OHMM)\"], color=\"teal\", ax=axes[1, 2])\n",
    "sns.boxplot(data[\"SW (V/V)\"], color=\"blue\", ax=axes[2, 0])\n",
    "sns.boxplot(data[\"VSH (V/V)\"], color=\"olive\", ax=axes[2, 1])\n",
    "sns.boxplot(data[\"TEMP (DEGC)\"], color=\"teal\", ax=axes[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap to visualize any collinearlity between variables\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Colormap definition\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "numeric_data = data.iloc[:, 1:-1]\n",
    "sns.heatmap(numeric_data.corr(), annot=True, fmt='.1g', vmin=-\n",
    "            1, vmax=1, center=0, cmap=cmap, square=True)\n",
    "# matplotlib issue with truncation of top and bottom row\n",
    "b, t = plt.ylim()\n",
    "b += 0.5  # Add 0.5 to the bottom\n",
    "t -= 0.5  # Subtract 0.5 from the top\n",
    "plt.ylim(b, t)  # update the ylim(bottom, top) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of plot to check collinearity between certain variables\n",
    "# looking into the correlation between Spacing and NN Spacing - All Zone/Same Zone\n",
    "sns.regplot(x='PHIF (V/V)', y='KLOGH (MD)', data=data)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate categorical columns\n",
    "columns_categ = ['WELL NAME', 'LITHOTYPE']\n",
    "data_cont = data.drop(data[columns_categ], axis=1)  # continous data\n",
    "# move response variable to end of dataframe\n",
    "data_cont = data_cont[[col for col in data_cont.columns if col != 'KLOGH (MD)'] + ['KLOGH (MD)']]\n",
    "data_cont.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "X = data_cont.iloc[:, :-1]\n",
    "y = data_cont.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Training X:', X_train.shape)\n",
    "print('Shape of Training y:', y_train.shape)\n",
    "print('Shape of Test X:', X_test.shape)\n",
    "print('Shape of Test y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some functions for regression\n",
    "# Regression\n",
    "\n",
    "def reg_metrics(test, pred):\n",
    "    '''Function returns basic metrics for regression models'''\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(test, pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(test, pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        metrics.mean_squared_error(test, pred)))\n",
    "    print('R Squared:', (metrics.r2_score(test, pred)))\n",
    "\n",
    "def reg_plot(test, pred):\n",
    "    '''Function returns a regression plot, in the form of a scatter plot'''\n",
    "    sns.regplot(x=test, y=pred, scatter_kws={\n",
    "                \"color\": \"black\"}, line_kws={\"color\": \"red\"})\n",
    "    plt.xlim(0, max(test))\n",
    "    plt.ylim(0, max(pred))\n",
    "    plt.title('Regression Results')\n",
    "    plt.xlabel('Test Data')\n",
    "    plt.ylabel('Model Prediction')\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot_comparison(test, pred):\n",
    "    '''Function returns a comparison between test data and predictions, in the form of line plot'''\n",
    "    sns.scatterplot(x=test.index, y=test.values, color='red', label='Test data')\n",
    "    sns.scatterplot(x=test.index, y=pred, color='blue', label='Predicted data')\n",
    "    plt.title('Prediction')\n",
    "    plt.xlabel('Observations')\n",
    "    plt.ylabel('Test and Predicted Values')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def line_plot_comparison(test, pred):\n",
    "    '''Function returns a comparison between test data and predictions, in the form of line plot'''\n",
    "    plt.plot(test.values, color='red', label='Test data')\n",
    "    plt.plot(pred, color='blue', label='Predicted data')\n",
    "    plt.title('Prediction')\n",
    "    plt.xlabel('Observations')\n",
    "    plt.ylabel('Test and Predicted Values')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MLR - Multi Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)  # training the algorithm\n",
    "print(lin_reg.intercept_)  # intercept\n",
    "print(lin_reg.coef_)  # coefficients\n",
    "# Prediction on test data\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "# Regression Plot - Linear Regression\n",
    "reg_plot(y_test, y_pred_lin)\n",
    "scatter_plot_comparison(y_test, y_pred_lin)\n",
    "# Metrics for Linear Regression\n",
    "reg_metrics(y_test, y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Support Vector Regression (SVR)\n",
    "# gaussian kernel selected due to non-linearity in dataset\n",
    "# Radial basis function - kernel is shown here, other available kernels include 'linear, sigmoid and polynomial'\n",
    "svr_reg = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_reg.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_svr = svr_reg.predict(X_test)\n",
    "# Regression Plot - SVR\n",
    "reg_plot(y_test, y_pred_svr)\n",
    "scatter_plot_comparison(y_test, y_pred_svr)\n",
    "# Metrics for SVR\n",
    "reg_metrics(y_test, y_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Decision Tree - Regression\n",
    "dt_reg = DecisionTreeRegressor(random_state=42)\n",
    "dt_reg.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_dt = dt_reg.predict(X_test)\n",
    "# Regression Plot - Decision Tree\n",
    "reg_plot(y_test, y_pred_dt)\n",
    "scatter_plot_comparison(y_test, y_pred_dt)\n",
    "# Metrics for Decision Tree\n",
    "reg_metrics(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Random Forest - Regression\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "# Regression Plot - Random Forest\n",
    "reg_plot(y_test, y_pred_rf)\n",
    "scatter_plot_comparison(y_test, y_pred_rf)\n",
    "# Metrics for Random Forest\n",
    "reg_metrics(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. XGBoost - Regression\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_xgb = xgb_reg.predict(X_test)\n",
    "# Regression Plot - XGBoost\n",
    "reg_plot(y_test, y_pred_xgb)\n",
    "scatter_plot_comparison(y_test, y_pred_xgb)\n",
    "# Metrics for XGBoost\n",
    "reg_metrics(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Artificial Neural Network\n",
    "# scaling the dataset\n",
    "std_scalar_X = StandardScaler()\n",
    "std_scalar_Y = StandardScaler()\n",
    "X_train_scaled = std_scalar_X.fit_transform(X_train)\n",
    "X_test_scaled = std_scalar_Y.fit_transform(X_test)\n",
    "\n",
    "def build_model():\n",
    "    ann_reg = keras.Sequential([\n",
    "        layers.Dense(32, activation='relu', input_shape=[len(X_train.keys())]),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1) ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    ann_reg.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    return ann_reg\n",
    "\n",
    "ann_reg = build_model()\n",
    "ann_reg.summary()\n",
    "\n",
    "history = ann_reg.fit(X_train_scaled, y_train.values, epochs=1000, validation_split=0.25, verbose=1)\n",
    "print(history.history.keys())\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "\n",
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_mse'])\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "y_pred_ann = ann_reg.predict(X_test_scaled).flatten()\n",
    "# Regression Plot - ANN\n",
    "reg_plot(y_test, y_pred_ann)\n",
    "scatter_plot_comparison(y_test, y_pred_ann)\n",
    "# Metrics for ANN\n",
    "reg_metrics(y_test, y_pred_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response variable in the classification is 'Lithotype' with all remaining features as input'\n",
    "data['LITHOTYPE'].value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "count_categ = data['LITHOTYPE'].value_counts()\n",
    "print(count_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As observed multiple categories are present, however 'other' won't be considered and\n",
    "# only the categories with frequency of more than 200 will be included, i.e. 3 categories\n",
    "data_categ = data[data['LITHOTYPE'].isin(count_categ[count_categ > 200].index)]\n",
    "data_categ = data_categ[data_categ['LITHOTYPE'] != 'OTHER']\n",
    "data_categ['LITHOTYPE'].value_counts()\n",
    "data_categ['LITHOTYPE'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categ.drop('WELL NAME', axis=1, inplace=True)\n",
    "data_categ.info()\n",
    "data_categ.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_categ.iloc[:, :-1]\n",
    "y = data_categ.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Training X:', X_train.shape)\n",
    "print('Shape of Training y:', y_train.shape)\n",
    "print('Shape of Test X:', X_test.shape)\n",
    "print('Shape of Test y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for classification metrics\n",
    "def clf_metrics(test, pred):\n",
    "    '''Function returns basic metrics for classification models'''\n",
    "    print('Classification Accuracy Score:', accuracy_score(test, pred))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(test, pred))\n",
    "    print('Classification Report: \\n', classification_report(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_logreg = clf_logreg.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SVC\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_svc = clf_svc.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Decision Tree Classifier\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_dt = clf_dt.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Random Forest Classifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. KNN\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. GaussianNB\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_gnb = clf_gnb.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LDA\n",
    "clf_lda = LinearDiscriminantAnalysis()\n",
    "clf_lda.fit(X_train, y_train)\n",
    "# Prediction on test data\n",
    "y_pred_lda = clf_lda.predict(X_test)\n",
    "# Accuracy Metrics\n",
    "clf_metrics(y_test, y_pred_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ANN\n",
    "\n",
    "dataset = data_categ.values\n",
    "X = dataset[:,0:12].astype(float)\n",
    "Y = dataset[:,13]\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# creating a dummy variable\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.25, random_state=42)\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(64, input_dim=12, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "ann_clf = baseline_model()\n",
    "ann_clf.summary()\n",
    "\n",
    "ann_classifier = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=1)\n",
    "# Cross Validation Score\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(ann_classifier, X, dummy_y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base Model Accuracy (Standard Deviation): %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset with all features\n",
    "data.info()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['WELL NAME', 'LITHOTYPE'], axis=1)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Clustering\n",
    "\n",
    "# finding the optimum number of clusters in the dataset\n",
    "clusters = []\n",
    "for i in range(1, 13):\n",
    "    km = cluster.KMeans(n_clusters=i).fit(X)\n",
    "    clusters.append(km.inertia_)\n",
    "\n",
    "# finding the number of clusters\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.lineplot(x=list(range(1, 13)), y=clusters, ax=ax)\n",
    "ax.set_title('Finding Optimum Number of Clusters')\n",
    "ax.set_xlabel('Clusters')\n",
    "ax.set_ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Visual Plot - 3 cluster\n",
    "km3 = cluster.KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=42).fit(X)\n",
    "X['Labels'] = km3.labels_\n",
    "X['Labels'].value_counts()\n",
    "sns.scatterplot(x=X['PHIF (V/V)'], y=X['KLOGH (MD)'], hue=X['Labels'], palette=sns.color_palette('hls', X['Labels'].nunique()))\n",
    "plt.title('KMeans with 3 Clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "\n",
    "data_categ.info()\n",
    "dataset = data_categ.values\n",
    "# One hot encoding example instead of LabelEncoder used earlier\n",
    "# Encoding - Convert categorical variables to numerical form, to execute machine learning algorithms\n",
    "X = data_categ.drop('LITHOTYPE', axis=1)\n",
    "y = data_categ['LITHOTYPE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 components can explain around 86.6% variablility \n",
    "# only 4 components will be used to test classification \n",
    "pca_4comp = PCA(n_components=4)\n",
    "X_train_4comp = pca_4comp.fit_transform(X_train)\n",
    "X_test_4comp = pca_4comp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with entire data\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with only 4 components\n",
    "classifier_4comp = RandomForestClassifier(random_state=42)\n",
    "classifier_4comp.fit(X_train_4comp, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred_4comp= classifier_4comp.predict(X_test_4comp)\n",
    "print(confusion_matrix(y_test, y_pred_4comp))\n",
    "print(accuracy_score(y_test, y_pred_4comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
